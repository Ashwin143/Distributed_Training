{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "solid-upset"
      },
      "source": [
        "At the end of the experiment, you will be able to:\n",
        "\n",
        "* load the data into RayDMatrix\n",
        "* train the XGBoost Ray model and save it\n",
        "* tune the Hyperparameters using Ray tune"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8newvEJqhW0"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "Compute demands for machine learning (ML) training have grown 10x every\n",
        "18 months since 2010. Over the same time period, the compute capabilities of\n",
        "AI accelerators such as GPUs and TPUs have less than doubled. This means\n",
        "that every year and a half organizations need 5x more AI accelerators/nodes\n",
        "to train the latest ML models and leverage cutting edge ML capabilities.\n",
        "Distributed computing is the only way to meet these requirements.\n",
        "\n",
        "While solutions such as AWS SageMaker and GCP Vertex AI have emerged\n",
        "to help organizations deal with scaling AI workloads, these solutions put\n",
        "significant constraints on how applications are developed and which libraries\n",
        "they can use. This makes it difficult to keep up with the latest models and\n",
        "algorithms, and freely integrate with the rapidly evolving open ML ecosystem.\n",
        "\n",
        "Ray, addresses these challenges head on by\n",
        "allowing ML engineers and developers to scale their workloads effortlessly\n",
        "from their laptops to the cloud without the need to build complex compute\n",
        "infrastructures."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Ray**\n",
        "\n",
        "Ray is an open-source unified framework for scaling AI and Python applications like machine learning. It provides the compute layer for parallel processing and reduce the need of a distributed systems expert. Ray minimizes the complexity of running your distributed individual and end-to-end machine learning workflows with these components:\n",
        "\n",
        "- Scalable libraries for common machine learning tasks such as data preprocessing, distributed training, hyperparameter tuning, reinforcement learning, and model serving.\n",
        "\n",
        "- Pythonic distributed computing primitives for parallelizing and scaling Python applications.\n",
        "\n",
        "- Integrations and utilities for integrating and deploying a Ray cluster with existing tools and infrastructure such as Kubernetes, AWS, GCP, and Azure.\n",
        "<br>\n",
        "\n",
        "Some common ML workloads that individuals, organizations, and companies leverage Ray to build their AI applications include:\n",
        "\n",
        "- Batch inference on CPUs and GPUs\n",
        "- Parallel training\n",
        "- Model serving\n",
        "- Distributed training of large models\n",
        "- Parallel hyperparameter tuning experiments\n",
        "- Reinforcement learning\n",
        "- ML platform\n"
      ],
      "metadata": {
        "id": "5LOtZlckE1vW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Ray framework**\n",
        "\n",
        "\n",
        "\n",
        "Ray's unified compute framework consists of three layers:\n",
        "\n",
        "- ***Ray AI Libraries:*** An open-source, Python, domain-specific set of libraries that equip ML engineers, data scientists, and researchers with a scalable and unified toolkit for ML applications.\n",
        "\n",
        "- ***Ray Core:*** An open-source, Python, general purpose, distributed computing library that enables ML engineers and Python developers to scale Python applications and accelerate machine learning workloads.\n",
        "\n",
        "- ***Ray Clusters:*** A set of worker nodes connected to a common Ray head node. Ray clusters can be fixed-size, or they can autoscale up and down according to the resources requested by applications running on the cluster.\n",
        "\n",
        "<br>\n",
        "\n",
        "Each of Ray's five native libraries distributes a specific ML task:\n",
        "\n",
        "- **`Data`**: Scalable, framework-agnostic data loading and transformation across training, tuning, and prediction\n",
        "\n",
        "- **`Train`**: Distributed multi-node and multi-core model training with fault tolerance that integrates with popular training libraries\n",
        "\n",
        "- **`Tune`**: Scalable hyperparameter tuning to optimize model performance\n",
        "\n",
        "- **`Serve`**: Scalable and programmable serving to deploy models for online inference, with optional microbatching to improve performance\n",
        "\n",
        "- **`RLlib`**: Scalable distributed reinforcement learning workloads\n"
      ],
      "metadata": {
        "id": "HfJAEecJHefq"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOno0OCY5KSD"
      },
      "source": [
        "Find the official Ray website [here](https://www.ray.io/), and its documentation [here](https://docs.ray.io/en/latest/ray-overview/index.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmE9xB1w4K8M"
      },
      "source": [
        "### Install necessary packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EXbmHKD_JBsx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fffd7f6d-5a78-4408-ec3d-d6acd7fcf882"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.4/138.4 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip -q install ray\n",
        "!pip -q install xgboost_ray"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3600ee25c8e"
      },
      "source": [
        "### Import necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LMFdp-Bw4leX"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "import xgboost as xgb\n",
        "from xgboost_ray import RayDMatrix, RayParams, train, predict\n",
        "from ray import tune"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRY_jIUFZtt7"
      },
      "source": [
        "### Load the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wxGCng--gYq3"
      },
      "outputs": [],
      "source": [
        "train_x, train_y = load_breast_cancer(return_X_y=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuMogwjLuj5-"
      },
      "source": [
        "### XGBoost-Ray uses the same API as core XGBoost\n",
        "\n",
        "There are only two differences:\n",
        "\n",
        "* Instead of using a `xgboost.DMatrix`, it uses `xgboost_ray.RayDMatrix` object\n",
        "\n",
        "* There is an additional `ray_params` parameter that is used to configure distributed training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kaoyQ7TburU0"
      },
      "outputs": [],
      "source": [
        "train_set = RayDMatrix(train_x, train_y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4WIhjlj2oT_"
      },
      "source": [
        "### Train the XGBoost Ray model and save it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "06u-IMu1I0c_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c54034b1-6168-4f4e-802a-91dc571a80fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-11-25 15:36:51,140\tINFO worker.py:1673 -- Started a local Ray instance.\n",
            "2023-11-25 15:36:56,597\tINFO main.py:1140 -- [RayXGBoost] Created 2 new actors (2 total actors). Waiting until actors are ready for training.\n",
            "2023-11-25 15:37:03,088\tINFO main.py:1191 -- [RayXGBoost] Starting XGBoost training.\n",
            "\u001b[36m(_RemoteRayXGBoostActor pid=3176)\u001b[0m [15:37:03] task [xgboost.ray]:133149315482336 got new rank 0\n",
            "2023-11-25 15:37:07,730\tINFO main.py:1708 -- [RayXGBoost] Finished XGBoost training on training data with total N=569 in 12.86 seconds (4.62 pure XGBoost training time).\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [15:37:07] WARNING: /workspace/src/c_api/c_api.cc:1240: Saving into deprecated binary model format, please consider using `json` or `ubj`. Model format will default to JSON in XGBoost 2.2 if not specified.\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        }
      ],
      "source": [
        "evals_result = {}\n",
        "bst = train(\n",
        "    {\n",
        "        \"objective\": \"binary:logistic\",\n",
        "        \"eval_metric\": [\"logloss\", \"error\"],\n",
        "    },\n",
        "    train_set,\n",
        "    evals_result=evals_result,\n",
        "    evals=[(train_set, \"train\")],\n",
        "    verbose_eval=False,\n",
        "    ray_params=RayParams(num_actors=2, cpus_per_actor=1))\n",
        "\n",
        "bst.save_model(\"model.xgb_ray\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_brYTFg2tZs"
      },
      "source": [
        "### Final training error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5dTgkUZ2Zcn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5000b8c0-92f2-4770-98bd-daedaa8f1b7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final training error: 0.0053\n"
          ]
        }
      ],
      "source": [
        "print(\"Final training error: {:.4f}\".format(\n",
        "    evals_result[\"train\"][\"error\"][-1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aP3LVX73lzKG"
      },
      "source": [
        "### Train the XGBoost model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c01Q3syvz66n"
      },
      "source": [
        "A simple prediction example. The data will be split across two actors. The result array will integrate this data in the correct order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WkJFmGsZJKCu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b2575f8-deda-40b5-fbe6-b76863dea063"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-11-25 15:54:59,979\tINFO main.py:1758 -- [RayXGBoost] Created 2 remote actors.\n",
            "2023-11-25 15:55:06,254\tINFO main.py:1775 -- [RayXGBoost] Starting XGBoost prediction.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.09144595 0.05673993 0.03008196 0.10851309 0.09144595 0.1226117\n",
            " 0.03008196 0.03145875 0.03795947 0.09715987 0.11452682 0.03008196\n",
            " 0.03008196 0.04623247 0.06943818 0.03008196 0.03738927 0.03008196\n",
            " 0.03008196 0.97716796 0.98008084 0.98008084 0.0675434  0.03008196\n",
            " 0.03008196 0.03620729 0.03974995 0.03008196 0.03008196 0.09527509\n",
            " 0.03008196 0.03008196 0.03008196 0.03008196 0.03008196 0.03008196\n",
            " 0.04384386 0.95125544 0.26743954 0.05803299 0.5169782  0.30979052\n",
            " 0.03008196 0.03145875 0.11796542 0.03620729 0.98008084 0.04324226\n",
            " 0.98008084 0.93069357 0.9776062  0.9790822  0.9698948  0.03261407\n",
            " 0.05082424 0.9698948  0.03008196 0.03145875 0.9790822  0.9698948\n",
            " 0.9731866  0.98008084 0.03008196 0.98008084 0.03145875 0.03145875\n",
            " 0.9700466  0.9698948  0.86911684 0.9698948  0.03008196 0.98008084\n",
            " 0.03008196 0.26402172 0.98008084 0.03008196 0.9691353  0.05734929\n",
            " 0.03958243 0.98008084 0.9700466  0.8453193  0.03008196 0.03008196\n",
            " 0.98008084 0.03008196 0.14372692 0.03008196 0.9427549  0.9228417\n",
            " 0.9702525  0.07124948 0.9445487  0.98008084 0.03008196 0.03008196\n",
            " 0.9790822  0.9675369  0.98008084 0.08050055 0.09838331 0.9790822\n",
            " 0.96856123 0.98008084 0.98008084 0.08512127 0.97137254 0.972742\n",
            " 0.03958243 0.98008084 0.98008084 0.9479173  0.7828473  0.98008084\n",
            " 0.98008084 0.97867364 0.9675369  0.03008196 0.03008196 0.04051078\n",
            " 0.98008084 0.03008196 0.03958243 0.9497272  0.98008084 0.9790822\n",
            " 0.12552918 0.0443966  0.938856   0.03008196 0.98008084 0.03008196\n",
            " 0.03261407 0.8907658  0.03261407 0.75316393 0.9675369  0.98008084\n",
            " 0.03620729 0.98008084 0.9790822  0.03261407 0.98008084 0.98008084\n",
            " 0.98008084 0.98008084 0.17123257 0.9735613  0.88343364 0.96568763\n",
            " 0.9615116  0.98008084 0.88908976 0.9790822  0.98008084 0.98008084\n",
            " 0.03008196 0.7762808  0.9790822  0.9790822  0.97687393 0.09591617\n",
            " 0.03008196 0.97867364 0.03746569 0.9727122  0.9790822  0.04648066\n",
            " 0.03008196 0.9785194  0.9698948  0.08497982 0.09144595 0.9675369\n",
            " 0.972742   0.9790822  0.98008084 0.03008196 0.97083193 0.9659314\n",
            " 0.03008196 0.03008196 0.0406477  0.9675369  0.05745313 0.9790822\n",
            " 0.04648066 0.9698948  0.9698948  0.98008084 0.04982003 0.83214355\n",
            " 0.94192004 0.20133358 0.03630884 0.98008084 0.03795947 0.06313886\n",
            " 0.03746569 0.03974995 0.98008084 0.03746569 0.03008196 0.03008196\n",
            " 0.98008084 0.18040861 0.98008084 0.13932122 0.87730044 0.8942108\n",
            " 0.03008196 0.98008084 0.05734929 0.06102134 0.03397038 0.05021824\n",
            " 0.97716796 0.98008084 0.03008196 0.03746569 0.98008084 0.98008084\n",
            " 0.98008084 0.03008196 0.9698948  0.9181721  0.9790822  0.95099175\n",
            " 0.9585643  0.04812844 0.03008196 0.9445931  0.941921   0.03008196\n",
            " 0.9790822  0.9700466  0.03008196 0.04648066 0.9262527  0.03008196\n",
            " 0.98008084 0.9532987  0.97137254 0.9698111  0.03008196 0.98008084\n",
            " 0.98008084 0.9584956  0.9214521  0.98008084 0.03008196 0.9790822\n",
            " 0.03008196 0.03008196 0.03008196 0.15147597 0.03008196 0.03620729\n",
            " 0.03008196 0.03008196 0.03008196 0.15759932 0.03008196 0.20570377\n",
            " 0.03008196 0.03008196 0.98008084 0.97397125 0.98008084 0.98008084\n",
            " 0.9727122  0.9698948  0.03008196 0.9790822  0.07765272 0.94513893\n",
            " 0.9790822  0.04051078 0.972742   0.98008084 0.03008196 0.959733\n",
            " 0.03008196 0.03008196 0.98008084 0.9790822  0.97129506 0.98008084\n",
            " 0.9691353  0.98008084 0.8793113  0.8940149  0.98008084 0.98008084\n",
            " 0.9790822  0.9790822  0.98008084 0.54328084 0.95907927 0.97867364\n",
            " 0.03008196 0.98008084 0.03008196 0.9698948  0.98008084 0.97697407\n",
            " 0.9790822  0.9790822  0.9790822  0.9790822  0.9790822  0.96744657\n",
            " 0.98008084 0.98008084 0.98008084 0.95578516 0.972742   0.03008196\n",
            " 0.97716796 0.9659314  0.98008084 0.07654875 0.97716796 0.03008196\n",
            " 0.98008084 0.9698948  0.9727122  0.9790822  0.03008196 0.03857466\n",
            " 0.03620729 0.98008084 0.9790822  0.9790822  0.9790822  0.03008196\n",
            " 0.98008084 0.03008196 0.98008084 0.03008196 0.88388485 0.98008084\n",
            " 0.98008084 0.03008196 0.9698948  0.98008084 0.9790822  0.9417705\n",
            " 0.9790822  0.97445923 0.9790822  0.03008196 0.03620729 0.03008196\n",
            " 0.98008084 0.98008084 0.9405863  0.9790822  0.98008084 0.9698948\n",
            " 0.972742   0.97867364 0.98008084 0.78658056 0.98008084 0.03008196\n",
            " 0.03008196 0.98008084 0.03008196 0.03008196 0.03008196 0.95183957\n",
            " 0.042814   0.04573814 0.98008084 0.8949583  0.92380065 0.9328913\n",
            " 0.98008084 0.18859395 0.97239256 0.98008084 0.97867364 0.98008084\n",
            " 0.98008084 0.16259243 0.98008084 0.98008084 0.98008084 0.03008196\n",
            " 0.98008084 0.98008084 0.03008196 0.03008196 0.98008084 0.98008084\n",
            " 0.8268216  0.98008084 0.98008084 0.98008084 0.03008196 0.98008084\n",
            " 0.98008084 0.96568763 0.9698948  0.98008084 0.90502375 0.9752459\n",
            " 0.03008196 0.98008084 0.89953864 0.9790822  0.97867364 0.8592128\n",
            " 0.11769029 0.98008084 0.9679539  0.03008196 0.98008084 0.9776062\n",
            " 0.98008084 0.943327   0.98008084 0.97058725 0.9162061  0.9790822\n",
            " 0.98008084 0.9679539  0.9790822  0.972742   0.03630884 0.98008084\n",
            " 0.03008196 0.03008196 0.9740068  0.0448303  0.98008084 0.98008084\n",
            " 0.9790822  0.9790822  0.94352734 0.05090874 0.9659314  0.98008084\n",
            " 0.05673993 0.9585643  0.03008196 0.9640666  0.9566246  0.03008196\n",
            " 0.97867364 0.03008196 0.95723265 0.9650936  0.9790822  0.94805354\n",
            " 0.9445931  0.9137997  0.9758236  0.95723265 0.03008196 0.03008196\n",
            " 0.9634344  0.98008084 0.98008084 0.9696536  0.97129506 0.98008084\n",
            " 0.03008196 0.924279   0.98008084 0.9234544  0.9253166  0.95514125\n",
            " 0.98008084 0.98008084 0.93002355 0.98008084 0.98008084 0.03620729\n",
            " 0.98008084 0.9640666  0.97239256 0.948528   0.8398718  0.97716796\n",
            " 0.95925575 0.03008196 0.98008084 0.11238775 0.9679539  0.86381257\n",
            " 0.03008196 0.9790822  0.98008084 0.9241328  0.9644855  0.98008084\n",
            " 0.03620729 0.03008196 0.9208975  0.04582075 0.98008084 0.03008196\n",
            " 0.9606986  0.9606986  0.98008084 0.98008084 0.93389726 0.03008196\n",
            " 0.98008084 0.9608389  0.03795947 0.95146865 0.19476202 0.97403514\n",
            " 0.03008196 0.03008196 0.95797086 0.98008084 0.96742904 0.03008196\n",
            " 0.9790822  0.97716796 0.98008084 0.98008084 0.96145505 0.972742\n",
            " 0.97203875 0.9698948  0.98008084 0.98008084 0.9790822  0.03008196\n",
            " 0.98008084 0.03008196 0.0737275  0.9585643  0.9758236  0.97697407\n",
            " 0.98008084 0.88192576 0.91490185 0.95723265 0.98008084 0.97397125\n",
            " 0.9790822  0.98008084 0.9698948  0.97697407 0.9776062  0.97867364\n",
            " 0.95723265 0.97867364 0.95723265 0.95723265 0.98008084 0.95514125\n",
            " 0.9702525  0.9418269  0.9678904  0.95072544 0.03008196 0.03008196\n",
            " 0.03008196 0.03008196 0.0394715  0.03008196 0.9758236 ]\n"
          ]
        }
      ],
      "source": [
        "dpred =RayDMatrix(train_x, train_y)\n",
        "bst = xgb.Booster(model_file=\"model.xgb_ray\")\n",
        "pred_ray = predict(bst, dpred, ray_params=RayParams(num_actors=2))\n",
        "\n",
        "print(pred_ray)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9E6n1LzUsnld"
      },
      "source": [
        "## Hyperparameter Optimization with Ray"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jzt3PmB94KyN"
      },
      "source": [
        "1. Put the XGBoost-Ray training call into a function accepting parameter configurations (`train_model` in the example below)\n",
        "2. Create a RayParams object\n",
        "\n",
        "3. Define the parameter search space (`config` dictionary)\n",
        "\n",
        "4. Call `tune.run()`:\n",
        "    * The metric parameter should contain the metric to optimized. Usually this consists of the prefix passed to the evals argument of `xgboost_ray.train()`, and an `eval_metric` passed in the XGBoost parameters (train-error in the example below)\n",
        "\n",
        "    * The mode should either be min or max, depending on whether the metric is to be minimized or maximized\n",
        "\n",
        "    * The `resources_per_actor` should be set using `ray_params.get_tune_resources()`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8k1fbqjhogkf"
      },
      "source": [
        "### Set the number of processes and the number of units per process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NEfL_oIiofoi"
      },
      "outputs": [],
      "source": [
        "num_actors = 4\n",
        "num_cpus_per_actor = 1\n",
        "\n",
        "ray_params = RayParams(\n",
        "    num_actors=num_actors, cpus_per_actor=num_cpus_per_actor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xpJrSWmqyHZ"
      },
      "source": [
        "### Define a function to train the XGBoost Ray model and save it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F3FFh_kEqq_v"
      },
      "outputs": [],
      "source": [
        "def train_model(config):\n",
        "    evals_result = {}\n",
        "    bst = train(\n",
        "    params=config,\n",
        "        dtrain=train_set,\n",
        "        evals_result=evals_result,\n",
        "        evals=[(train_set, \"train\")],\n",
        "        verbose_eval=False,\n",
        "        ray_params=ray_params)\n",
        "        # params=config,\n",
        "        # dtrain=train_set,\n",
        "        # evals_result=evals_result,\n",
        "        # evals=[(train_set, \"train\")],\n",
        "        # verbose_eval=False,\n",
        "        # ray_params=ray_params)\n",
        "    bst.save_model(\"model.xgb_ray\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4HoHUh4q-4f"
      },
      "source": [
        "### Specify the hyperparameter search space."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2LUiYzpLrBcZ"
      },
      "outputs": [],
      "source": [
        "config = {\n",
        "    \"tree_method\": \"approx\",\n",
        "    \"objective\": \"binary:logistic\",\n",
        "    \"eval_metric\": [\"logloss\", \"error\"],\n",
        "    \"eta\": tune.loguniform(1e-4, 1e-1),\n",
        "    \"subsample\": tune.uniform(0.5, 1.0),\n",
        "    \"max_depth\": tune.randint(1, 9)\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjFqujWntTxY"
      },
      "source": [
        "### Train and display the results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPzSWN4tshdf"
      },
      "source": [
        "Ray Tune uses Ray to start multiple distributed trials with different hyperparameter configurations. If used with XGBoost-Ray, these trials will then start their own distributed training jobs.\n",
        "\n",
        "XGBoost-Ray automatically reports evaluation results back to Ray Tune."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8FehAF2szlf"
      },
      "source": [
        "documentation [here](https://xgboost.readthedocs.io/en/stable/tutorials/ray.html#hyperparameter-optimization)\n",
        "\n",
        "\n",
        "Make sure to use the `get_tune_resources` method to set the `resources_per_trial`\n",
        "\n",
        "This will make sure that each trial has the necessary resources available to start their distributed training jobs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "No1YT3pyJgUG",
        "outputId": "22f12504-94c4-4f6f-8fe3-73c782410b3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-11-25 15:57:43,635\tINFO tune.py:595 -- [output] This will use the new output engine with verbosity 2. To disable the new output and use the legacy output engine, set the environment variable RAY_AIR_NEW_OUTPUT=0. For more information, please see https://github.com/ray-project/ray/issues/36949\n",
            "2023-11-25 15:57:43,653\tINFO tensorboardx.py:178 -- pip install \"ray[tune]\" to see TensorBoard files.\n",
            "2023-11-25 15:57:43,656\tWARNING callback.py:137 -- The TensorboardX logger cannot be instantiated because either TensorboardX or one of it's dependencies is not installed. Please make sure you have the latest version of TensorboardX installed: `pip install -U tensorboardx`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------------------------------------+\n",
            "| Configuration for experiment     train_model_2023-11-25_15-57-43   |\n",
            "+--------------------------------------------------------------------+\n",
            "| Search algorithm                 BasicVariantGenerator             |\n",
            "| Scheduler                        FIFOScheduler                     |\n",
            "| Number of trials                 4                                 |\n",
            "+--------------------------------------------------------------------+\n",
            "\n",
            "View detailed results here: /root/ray_results/train_model_2023-11-25_15-57-43\n",
            "\n",
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 15:57:43. Total running time: 0s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n",
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 15:58:13. Total running time: 30s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-11-25 15:58:44,040\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 4.0 CPUs and 0 GPUs per trial, but the cluster only has 2.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 15:58:43. Total running time: 1min 0s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n",
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 15:59:13. Total running time: 1min 30s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-11-25 15:59:44,055\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 4.0 CPUs and 0 GPUs per trial, but the cluster only has 2.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 15:59:43. Total running time: 2min 0s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n",
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:00:14. Total running time: 2min 30s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-11-25 16:00:44,081\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 4.0 CPUs and 0 GPUs per trial, but the cluster only has 2.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:00:44. Total running time: 3min 0s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n",
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:01:14. Total running time: 3min 30s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-11-25 16:01:44,092\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 4.0 CPUs and 0 GPUs per trial, but the cluster only has 2.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:01:44. Total running time: 4min 0s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n",
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:02:14. Total running time: 4min 30s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-11-25 16:02:44,112\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 4.0 CPUs and 0 GPUs per trial, but the cluster only has 2.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:02:44. Total running time: 5min 0s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n",
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:03:14. Total running time: 5min 30s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-11-25 16:03:44,120\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 4.0 CPUs and 0 GPUs per trial, but the cluster only has 2.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:03:44. Total running time: 6min 0s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n",
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:04:14. Total running time: 6min 30s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-11-25 16:04:44,159\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 4.0 CPUs and 0 GPUs per trial, but the cluster only has 2.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:04:44. Total running time: 7min 0s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n",
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:05:14. Total running time: 7min 30s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-11-25 16:05:44,179\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 4.0 CPUs and 0 GPUs per trial, but the cluster only has 2.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:05:44. Total running time: 8min 0s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n",
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:06:14. Total running time: 8min 30s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-11-25 16:06:44,196\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 4.0 CPUs and 0 GPUs per trial, but the cluster only has 2.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:06:44. Total running time: 9min 0s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n",
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:07:14. Total running time: 9min 30s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-11-25 16:07:44,246\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 4.0 CPUs and 0 GPUs per trial, but the cluster only has 2.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:07:44. Total running time: 10min 0s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n",
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:08:14. Total running time: 10min 30s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-11-25 16:08:44,270\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 4.0 CPUs and 0 GPUs per trial, but the cluster only has 2.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:08:44. Total running time: 11min 0s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n",
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:09:14. Total running time: 11min 30s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-11-25 16:09:44,309\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 4.0 CPUs and 0 GPUs per trial, but the cluster only has 2.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:09:44. Total running time: 12min 0s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n",
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:10:14. Total running time: 12min 30s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-11-25 16:10:44,330\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 4.0 CPUs and 0 GPUs per trial, but the cluster only has 2.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:10:44. Total running time: 13min 0s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n",
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:11:14. Total running time: 13min 30s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-11-25 16:11:44,351\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 4.0 CPUs and 0 GPUs per trial, but the cluster only has 2.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:11:44. Total running time: 14min 0s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n",
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:12:14. Total running time: 14min 30s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-11-25 16:12:44,374\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 4.0 CPUs and 0 GPUs per trial, but the cluster only has 2.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:12:44. Total running time: 15min 0s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n",
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:13:14. Total running time: 15min 30s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-11-25 16:13:44,394\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 4.0 CPUs and 0 GPUs per trial, but the cluster only has 2.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:13:44. Total running time: 16min 0s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n",
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:14:14. Total running time: 16min 30s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-11-25 16:14:44,437\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 4.0 CPUs and 0 GPUs per trial, but the cluster only has 2.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:14:44. Total running time: 17min 0s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n",
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:15:14. Total running time: 17min 30s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-11-25 16:15:44,466\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 4.0 CPUs and 0 GPUs per trial, but the cluster only has 2.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:15:44. Total running time: 18min 0s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n",
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:16:14. Total running time: 18min 31s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-11-25 16:16:44,485\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 4.0 CPUs and 0 GPUs per trial, but the cluster only has 2.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:16:44. Total running time: 19min 1s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n",
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:17:14. Total running time: 19min 31s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-11-25 16:17:44,510\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 4.0 CPUs and 0 GPUs per trial, but the cluster only has 2.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:17:44. Total running time: 20min 1s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n",
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:18:14. Total running time: 20min 31s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-11-25 16:18:44,535\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 4.0 CPUs and 0 GPUs per trial, but the cluster only has 2.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:18:44. Total running time: 21min 1s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n",
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:19:14. Total running time: 21min 31s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-11-25 16:19:44,547\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 4.0 CPUs and 0 GPUs per trial, but the cluster only has 2.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:19:44. Total running time: 22min 1s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n",
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:20:14. Total running time: 22min 31s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-11-25 16:20:44,574\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 4.0 CPUs and 0 GPUs per trial, but the cluster only has 2.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:20:44. Total running time: 23min 1s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n",
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:21:14. Total running time: 23min 31s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-11-25 16:21:44,591\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 4.0 CPUs and 0 GPUs per trial, but the cluster only has 2.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:21:44. Total running time: 24min 1s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n",
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:22:14. Total running time: 24min 31s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-11-25 16:22:44,619\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 4.0 CPUs and 0 GPUs per trial, but the cluster only has 2.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:22:44. Total running time: 25min 1s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n",
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:23:14. Total running time: 25min 31s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-11-25 16:23:44,643\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 4.0 CPUs and 0 GPUs per trial, but the cluster only has 2.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:23:44. Total running time: 26min 1s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n",
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:24:14. Total running time: 26min 31s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-11-25 16:24:44,692\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 4.0 CPUs and 0 GPUs per trial, but the cluster only has 2.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:24:44. Total running time: 27min 1s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n",
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:25:14. Total running time: 27min 31s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-11-25 16:25:44,720\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 4.0 CPUs and 0 GPUs per trial, but the cluster only has 2.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:25:44. Total running time: 28min 1s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n",
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:26:14. Total running time: 28min 31s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-11-25 16:26:44,734\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 4.0 CPUs and 0 GPUs per trial, but the cluster only has 2.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:26:44. Total running time: 29min 1s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n",
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:27:14. Total running time: 29min 31s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-11-25 16:27:44,752\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 4.0 CPUs and 0 GPUs per trial, but the cluster only has 2.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:27:44. Total running time: 30min 1s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n",
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:28:15. Total running time: 30min 31s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-11-25 16:28:44,760\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 4.0 CPUs and 0 GPUs per trial, but the cluster only has 2.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:28:45. Total running time: 31min 1s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n",
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:29:15. Total running time: 31min 31s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-11-25 16:29:44,785\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 4.0 CPUs and 0 GPUs per trial, but the cluster only has 2.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:29:45. Total running time: 32min 1s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n",
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:30:15. Total running time: 32min 31s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-11-25 16:30:44,806\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 4.0 CPUs and 0 GPUs per trial, but the cluster only has 2.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:30:45. Total running time: 33min 1s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n",
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:31:15. Total running time: 33min 31s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-11-25 16:31:44,826\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 4.0 CPUs and 0 GPUs per trial, but the cluster only has 2.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:31:45. Total running time: 34min 1s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n",
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:32:15. Total running time: 34min 31s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-11-25 16:32:44,832\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 4.0 CPUs and 0 GPUs per trial, but the cluster only has 2.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:32:45. Total running time: 35min 1s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n",
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:33:15. Total running time: 35min 31s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-11-25 16:33:44,853\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 4.0 CPUs and 0 GPUs per trial, but the cluster only has 2.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:33:45. Total running time: 36min 1s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n",
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:34:15. Total running time: 36min 31s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-11-25 16:34:44,860\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 4.0 CPUs and 0 GPUs per trial, but the cluster only has 2.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:34:45. Total running time: 37min 1s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n",
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:35:15. Total running time: 37min 31s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-11-25 16:35:44,954\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 4.0 CPUs and 0 GPUs per trial, but the cluster only has 2.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:35:45. Total running time: 38min 1s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n",
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:36:15. Total running time: 38min 31s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-11-25 16:36:45,057\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 4.0 CPUs and 0 GPUs per trial, but the cluster only has 2.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:36:45. Total running time: 39min 1s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n",
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:37:15. Total running time: 39min 31s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-11-25 16:37:45,112\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 4.0 CPUs and 0 GPUs per trial, but the cluster only has 2.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:37:45. Total running time: 40min 2s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n",
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:38:15. Total running time: 40min 32s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-11-25 16:38:45,135\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 4.0 CPUs and 0 GPUs per trial, but the cluster only has 2.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:38:45. Total running time: 41min 2s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n",
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:39:15. Total running time: 41min 32s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-11-25 16:39:45,150\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 4.0 CPUs and 0 GPUs per trial, but the cluster only has 2.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:39:45. Total running time: 42min 2s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n",
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:40:15. Total running time: 42min 32s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-11-25 16:40:45,179\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 4.0 CPUs and 0 GPUs per trial, but the cluster only has 2.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:40:45. Total running time: 43min 2s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n",
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:41:15. Total running time: 43min 32s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-11-25 16:41:45,200\tWARNING insufficient_resources_manager.py:163 -- Ignore this message if the cluster is autoscaling. No trial is running and no new trial has been started within the last 60 seconds. This could be due to the cluster not having enough resources available. You asked for 4.0 CPUs and 0 GPUs per trial, but the cluster only has 2.0 CPUs and 0 GPUs available. Stop the tuning and adjust the required resources (e.g. via the `ScalingConfig` or `resources_per_trial`, or `num_workers` for rllib), or add more resources to your cluster.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:41:45. Total running time: 44min 2s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-11-25 16:41:54,400\tWARNING tune.py:186 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
            "2023-11-25 16:41:54,419\tWARNING tune.py:1062 -- Experiment has been interrupted, but the most recent state was saved.\n",
            "Resume experiment with: tune.run(..., resume=True)\n",
            "2023-11-25 16:41:54,432\tWARNING experiment_analysis.py:185 -- Failed to fetch metrics for 4 trial(s):\n",
            "- train_model_5e852_00000: FileNotFoundError('Could not fetch metrics for train_model_5e852_00000: both result.json and progress.csv were not found at /root/ray_results/train_model_2023-11-25_15-57-43/train_model_5e852_00000_0_eta=0.0979,max_depth=1,subsample=0.7729_2023-11-25_15-57-43')\n",
            "- train_model_5e852_00001: FileNotFoundError('Could not fetch metrics for train_model_5e852_00001: both result.json and progress.csv were not found at /root/ray_results/train_model_2023-11-25_15-57-43/train_model_5e852_00001_1_eta=0.0002,max_depth=1,subsample=0.9834_2023-11-25_15-57-43')\n",
            "- train_model_5e852_00002: FileNotFoundError('Could not fetch metrics for train_model_5e852_00002: both result.json and progress.csv were not found at /root/ray_results/train_model_2023-11-25_15-57-43/train_model_5e852_00002_2_eta=0.0002,max_depth=2,subsample=0.8555_2023-11-25_15-57-43')\n",
            "- train_model_5e852_00003: FileNotFoundError('Could not fetch metrics for train_model_5e852_00003: both result.json and progress.csv were not found at /root/ray_results/train_model_2023-11-25_15-57-43/train_model_5e852_00003_3_eta=0.0065,max_depth=7,subsample=0.5089_2023-11-25_15-57-43')\n",
            "2023-11-25 16:41:54,435\tWARNING experiment_analysis.py:575 -- Could not find best trial. Did you pass the correct `metric` parameter?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial status: 4 PENDING\n",
            "Current time: 2023-11-25 16:41:54. Total running time: 44min 10s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name                status             eta     subsample     max_depth |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_model_5e852_00000   PENDING    0.0979471        0.772874             1 |\n",
            "| train_model_5e852_00001   PENDING    0.000179901      0.983443             1 |\n",
            "| train_model_5e852_00002   PENDING    0.000161912      0.855457             2 |\n",
            "| train_model_5e852_00003   PENDING    0.00651198       0.508894             7 |\n",
            "+------------------------------------------------------------------------------+\n",
            "\n",
            "Best hyperparameters None\n"
          ]
        }
      ],
      "source": [
        "analysis = tune.run(\n",
        "    train_model,\n",
        "    config=config,\n",
        "    metric=\"train-error\",\n",
        "    mode=\"min\",\n",
        "    num_samples=4,\n",
        "    resources_per_trial=ray_params.get_tune_resources())\n",
        "print(\"Best hyperparameters\", analysis.best_config)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}